{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "sys.path.insert(0,\"..\")\n",
    "from src.evaluation.evaluate import evaluate_df,evaluate_sentence\n",
    "from src.data.make_dataset import recompose, additional_cleaners\n",
    "from camel_tools.utils.charsets import UNICODE_PUNCT_CHARSET\n",
    "from src.predict.mle_predict import apply_mle, load_mle_model, tokenize_skiphyph\n",
    "from src.predict import translit_rules\n",
    "from src.train.mle_train import train_mle, load_traindf\n",
    "from Levenshtein import ratio\n",
    "from src.madamira.analyse import load_analysis, parse_analyser_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = Path(os.getcwd()).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{home}/data/processed/train.tsv',delimiter='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdf = train[train['ar'].apply(lambda x: 'خريستو' in x)]\n",
    "# testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "# locmap = translit_rules.load_loc_mappings()\n",
    "# exceptional = translit_rules.load_exceptional_spellings()\n",
    "\n",
    "# tok = 'abc'\n",
    "# translit_tok = translit_rules.translit_loc_token('يسشابس',locmap,exceptional)\n",
    "# translit_tok\n",
    "# ratio(tok,translit_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# of misaligned sentences skipped: 134\n"
     ]
    }
   ],
   "source": [
    "# mledf = train_mle(train,size_ratio=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_csv(f'{Path(os.getcwd()).parent}/data/processed/dev.tsv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mledict = load_mle_model(size=1,as_df=True)#mle_model_tsv=f'{home}/models/mle/size1.0.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     source   target  freq\n",
       "8674  تسهيل  Tasʹhīl    14"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>target</th>\n      <th>freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8674</th>\n      <td>تسهيل</td>\n      <td>Tasʹhīl</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "mledict[mledict['source']=='تسهيل']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lev_ratio(dfrow,col1,col2):\n",
    "    str1 = str(dfrow[col1]).lower()\n",
    "    str2 = str(dfrow[col2]).lower()\n",
    "    return ratio(str1,str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "deveval = pd.read_csv(f'{home}/evaluation/dev/size1.0.tsv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deveval[deveval['misaligned']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "match_ignore_case\n",
       "True     0.865683\n",
       "False    0.134317\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 317
    }
   ],
   "source": [
    "deveval.value_counts('match_ignore_case',normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev TODO: tweak mle to preserve capitalization only for non-initial toks\n",
    "testeval = evaluation[evaluation['match_ignore_case']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_csv(f'{home}/data/processed/dev.tsv',delimiter='\\t').set_index('sentID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'thawāb al-Aʻmāl wa ;'"
      ]
     },
     "metadata": {},
     "execution_count": 228
    }
   ],
   "source": [
    "apply_mle(testsent['ar'],mledict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "translit_morph_predictions = pd.read_csv(f'{home}/predictions_out/translit_rules/dev/translit_morph.tsv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translit_morph_predictions = pd.read_csv(f'{home}/predictions_out/translit_rules/dev/translit_morph.tsv',delimiter='\\t')\n",
    "def apply_mle_translit_morph_backoff(sentence,backoff_sentences,sent_index):\n",
    "    predict_mle = []\n",
    "    for tok_idx, tok in enumerate(tokenize_skiphyph(sentence).split()):\n",
    "        if tok in mledict:\n",
    "            mle_tok = mledict[tok]\n",
    "        else:\n",
    "            bckf_sent = backoff_sentences[sent_index]\n",
    "            bckf_tokens = tokenize_skiphyph(bckf_sent).split()\n",
    "            mle_tok = bckf_tokens[tok_idx]\n",
    "        predict_mle.append(mle_tok)\n",
    "    return recompose(' '.join(predict_mle),mode='rom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mle_translit_morph_backoff(sentence,mledict,backoff_sentences,sent_index):\n",
    "    predict_mle = []\n",
    "    for tok_idx, tok in enumerate(tokenize_skiphyph(sentence).split()):\n",
    "        if tok in mledict:\n",
    "            mle_tok = mledict[tok]\n",
    "        else:\n",
    "            bckf_sent = backoff_sentences[sent_index]\n",
    "            bckf_tokens = tokenize_skiphyph(bckf_sent).split()\n",
    "            mle_tok = bckf_tokens[tok_idx]\n",
    "        predict_mle.append(mle_tok)\n",
    "    return recompose(' '.join(predict_mle),mode='rom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translit_morph_predictions = list(translit_morph_predictions[0].values)\n",
    "    predictions = []\n",
    "    for sent_idx, sent in enumerate(ar_lines):\n",
    "        try:\n",
    "            sent_prediction = apply_mle_translit_morph_backoff(sent,mledict=mledict,backoff_sentences=translit_morph_predictions,sent_index=sent_idx)\n",
    "        except:\n",
    "            print(sent)\n",
    "            print()\n",
    "            print(translit_morph_predictions[sent_idx])\n",
    "            exit()\n",
    "        predictions.append(sent_prediction)\n",
    "\n",
    "    predictions = pd.DataFrame(predictions)"
   ]
  }
 ]
}